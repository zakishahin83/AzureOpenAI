{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/en/latest/modules/agents/getting_started.html \n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate, \n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    \n",
    ")\n",
    "from langchain.schema import ( \n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_endpoint: https://lnc-eastus-openai.openai.azure.com/\n",
      "gpt4_key: **********\n",
      "gpt4_region: eastus\n",
      "gpt4_modelid_4k: gpt-4-0314\n",
      "gpt4_modelid_32k: gpt-4-32k-0314\n",
      "gpt4_api_version: 2023-03-15-preview\n",
      "chatgpt_api_key: **********\n",
      "chatgpt_region: southcentralus\n",
      "chatgpt_endpoint: https://magopenai.openai.azure.com/\n",
      "oai_api_key: **********\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# get above env variables using os.environ.get and use provided values as defaults\n",
    "gpt4_endpoint = os.environ.get('gpt4_endpoint', 'https://lnc-eastus-openai.openai.azure.com/')\n",
    "gpt4_key = os.environ.get('gpt4_key', '121221')\n",
    "gpt4_region = os.environ.get('gpt4_region', 'eastus')\n",
    "gpt4_modelid_4k = os.environ.get('gpt4_modelid_4k', 'gpt-4-0314')\n",
    "gpt4_modelid_32k = os.environ.get('gpt4_modelid_32k', 'gpt-4-32k-0314')\n",
    "gpt4_api_version = os.environ.get('gpt4_api_version', '2023-03-15-preview')\n",
    "\n",
    "\n",
    "# get the above from os.environ.get and use provided values as defaults\n",
    "chatgpt_api_key = os.environ.get('chatgpt_api_key', '121212121212')\n",
    "chatgpt_region = os.environ.get('chatgpt_region', 'southcentralus')\n",
    "chatgpt_endpoint = os.environ.get('chatgpt_endpoint', 'https://magopenai.openai.azure.com/')\n",
    "chatgpt_api_version = os.environ.get('chatgpt_api_version', '2021-03-15-preview')\n",
    "\n",
    "oai_api_key = os.environ.get('oai_api_key', '121212121212')\n",
    "\n",
    "print(f'gpt4_endpoint: {gpt4_endpoint}')\n",
    "print(f'gpt4_key: **********')\n",
    "print(f'gpt4_region: {gpt4_region}')\n",
    "print(f'gpt4_modelid_4k: {gpt4_modelid_4k}')\n",
    "print(f'gpt4_modelid_32k: {gpt4_modelid_32k}')\n",
    "print(f'gpt4_api_version: {gpt4_api_version}')\n",
    "print(f'chatgpt_api_key: **********')\n",
    "print(f'chatgpt_region: {chatgpt_region}')\n",
    "print(f'chatgpt_endpoint: {chatgpt_endpoint}')\n",
    "print(f'oai_api_key: **********')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must set openai_api_base correctly -- but since thats done in the next call, AzureOpenAI instance will work\n",
    "azure_llm = AzureOpenAI(\n",
    "    deployment_name='text-davinci-003', \n",
    "    model_name='text-davinci-003', \n",
    "    openai_api_key=chatgpt_api_key,\n",
    "        model_kwargs={\n",
    "        \"api_base\": chatgpt_endpoint, \n",
    "        \"api_type\": \"azure\", \n",
    "        \"api_version\": chatgpt_api_version,\n",
    "    },\n",
    "\n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_chat_model = AzureChatOpenAI(\n",
    "    deployment_name=gpt4_modelid_4k,\n",
    "    model_name=gpt4_modelid_4k,\n",
    "    openai_api_key=gpt4_key,\n",
    "    openai_api_base=gpt4_endpoint,\n",
    "    openai_api_version=gpt4_api_version,\n",
    "    verbose=True, \n",
    "    streaming=True,\n",
    "    temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api_base': 'https://magopenai.openai.azure.com/',\n",
      " 'api_type': 'azure',\n",
      " 'api_version': '2023-03-15-preview',\n",
      " 'best_of': 1,\n",
      " 'deployment_name': 'text-davinci-003',\n",
      " 'frequency_penalty': 0,\n",
      " 'logit_bias': {},\n",
      " 'max_tokens': 256,\n",
      " 'model_name': 'text-davinci-003',\n",
      " 'n': 1,\n",
      " 'presence_penalty': 0,\n",
      " 'request_timeout': None,\n",
      " 'temperature': 0.7,\n",
      " 'top_p': 1}\n",
      "True\n",
      "<class 'langchain.llms.openai.BaseOpenAI'>\n",
      "{'engine': 'gpt-4-0314',\n",
      " 'max_tokens': None,\n",
      " 'model': 'gpt-4-0314',\n",
      " 'model_name': 'gpt-4-0314',\n",
      " 'n': 1,\n",
      " 'request_timeout': 60,\n",
      " 'stream': True,\n",
      " 'temperature': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain.llms import BaseLLM\n",
    "pprint(azure_llm._identifying_params)\n",
    "#cast azure_llm to BaseLLM\n",
    "print(isinstance(azure_llm, BaseLLM))\n",
    "# access parent class\n",
    "print(azure_llm.__class__.__base__)\n",
    "pprint(azure_chat_model._identifying_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI'm doing well, thank you! How about you?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Hello, I am a chatbot. How are you today?\"\n",
    "azure_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! As an AI, I don't have feelings or emotions, but I'm here to help you with any questions or concerns you may have. How can I assist you today?\", additional_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_chat_model([HumanMessage(content=prompt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: text-davinci-003, model: text-davinci-003\n",
      "id: gpt-35-turbo_v0301, model: gpt-35-turbo\n",
      "id: gpt-4-0314, model: gpt-4\n",
      "id: gpt-4-32k-0314, model: gpt-4-32k\n",
      "id: text-embedding-ada-002, model: text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = gpt4_key\n",
    "openai.api_base = gpt4_endpoint\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = gpt4_api_version\n",
    "\n",
    "# iterate over openai.Deployment\n",
    "for d in openai.Deployment.list()['data']: \n",
    "    print(f'id: {d[\"id\"]}, model: {d[\"model\"]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure_llm (AzureOpenAI): True\n",
      "azure_llm (BaseLLM): True\n",
      "azure_chat_model (AzureOpenAI): False\n",
      "azure_chat_model (BaseLLM): False\n",
      "azure_chat_model (AzureChatOpenAI): True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if chat_model is an instance of AzureChatOpenAI\n",
    "from langchain.llms import BaseLLM, GPT4All\n",
    "print(f\"azure_llm (AzureOpenAI): {isinstance(azure_llm, AzureOpenAI)}\")\n",
    "# isinstance(azure_llm, BaseLLM)\n",
    "print(f\"azure_llm (BaseLLM): {isinstance(azure_llm, BaseLLM)}\")\n",
    "print(f\"azure_chat_model (AzureOpenAI): {isinstance(azure_chat_model, AzureOpenAI)}\")\n",
    "print(f\"azure_chat_model (BaseLLM): {isinstance(azure_chat_model, BaseLLM)}\")\n",
    "print(f\"azure_chat_model (AzureChatOpenAI): {isinstance(azure_chat_model, AzureChatOpenAI)}\")\n",
    "isinstance(GPT4All, BaseLLM)\n",
    "\n",
    "# does GPT4All extend BaseLLM?\n",
    "issubclass(GPT4All, BaseLLM)\n",
    "issubclass(AzureOpenAI, BaseLLM)\n",
    "issubclass(AzureChatOpenAI, BaseLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Config', '__abstractmethods__', '__annotations__', '__call__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_agenerate', '_calculate_keys', '_combine_llm_outputs', '_copy_and_set_values', '_create_chat_result', '_create_message_dicts', '_create_retry_decorator', '_decompose_class', '_default_params', '_enforce_dict_if_root', '_generate', '_get_value', '_identifying_params', '_init_private_attributes', '_iter', 'agenerate', 'agenerate_prompt', 'build_extra', 'call_as_llm', 'completion_with_retry', 'construct', 'copy', 'dict', 'from_orm', 'generate', 'generate_prompt', 'get_num_tokens', 'get_num_tokens_from_messages', 'json', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'set_callback_manager', 'update_forward_refs', 'validate', 'validate_environment']\n",
      "Extra.ignore\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "# import HumanMessage\n",
    "\n",
    "\n",
    "print(dir(langchain.chat_models.AzureChatOpenAI))\n",
    "print(AzureChatOpenAI.Config.extra)\n",
    "\n",
    "azure_chat_model.call_as_llm(\"Hello, my name is John. What is your name?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a small village on the planet Zog, there lived a young boy named Zippy. Zippy was not like the other children in the village. He had a wild imagination and a thirst for adventure. He would often daydream about exploring the universe and discovering new planets.\n"
     ]
    }
   ],
   "source": [
    "azure_chat_model.streaming = False\n",
    "resp = azure_chat_model(\n",
    "    [HumanMessage(content=\"Write me a kids scifi story, starts with 'Once upon a time...'\")],\n",
    "    stop=[\"\\n\", \"Human:\", \"AI:\"],\n",
    "    )\n",
    "\n",
    "if azure_chat_model.streaming is not True: \n",
    "    print(resp.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a small village on the planet Zog, there lived a young boy named Zippy. Zippy was not like the other children in the village. He had a wild imagination and a thirst for adventure. He would often daydream about exploring the universe and discovering new planets.\n",
      "\n",
      "One day, while Zippy was playing in the fields, he stumbled upon a strange-looking rock. It was unlike any rock he had ever seen before. It was smooth and shiny, and it seemed to glow with a mysterious energy. Zippy picked up the rock and felt a sudden surge of power coursing through his body.\n",
      "\n",
      "As he held the rock, Zippy noticed that it began to change shape. It transformed into a small, metallic device with buttons and dials. Zippy couldn't believe his eyes. He had found a real-life spaceship!\n",
      "\n",
      "Without hesitation, Zippy climbed into the tiny spaceship and began to explore its controls. He pressed a button, and the spaceship's engines roared to life. The spaceship lifted off the ground and soared into the sky, leaving the village far behind.\n",
      "\n",
      "Zippy was filled with excitement as he traveled through space. He visited planets with purple skies and green oceans, and he met creatures that were both strange and wonderful. On one planet, he encountered a race of beings made entirely of water. On another, he discovered a city built on the back of a giant, floating turtle.\n",
      "\n",
      "As Zippy continued his journey, he began to learn more about the universe and its many mysteries. He discovered that the spaceship he had found was actually a gift from an ancient race of beings known as the Star Keepers. The Star Keepers had once been the guardians of the universe, but they had vanished long ago, leaving behind their powerful technology.\n",
      "\n",
      "Zippy knew that he had been chosen to carry on the legacy of the Star Keepers. He vowed to use the spaceship and its incredible powers to protect the universe from danger and to help those in need.\n",
      "\n",
      "One day, Zippy received a distress signal from a nearby planet. The planet was being threatened by a giant space monster that was devouring everything in its path. Zippy knew that he had to act quickly to save the planet and its inhabitants.\n",
      "\n",
      "He raced to the planet in his spaceship and confronted the space monster. Using the spaceship's powerful weapons, Zippy fought the monster in an epic battle that raged across the cosmos. In the end, Zippy was victorious, and the space monster was defeated.\n",
      "\n",
      "The grateful inhabitants of the planet hailed Zippy as a hero. They thanked him for saving their world and presented him with a special gift: a magical crystal that would allow him to communicate with the Star Keepers.\n",
      "\n",
      "With the crystal in hand, Zippy continued his adventures across the universe. He made many new friends and encountered countless wonders. And through it all, he never forgot his mission to protect the universe and carry on the legacy of the Star Keepers.\n",
      "\n",
      "And so, the legend of Zippy, the young hero from the planet Zog, spread throughout the cosmos. His name became synonymous with courage, kindness, and adventure. And as he traveled the stars, Zippy knew that he was fulfilling his destiny as the universe's greatest guardian.\n",
      "\n",
      "And they all lived happily ever after, among the stars.The End!\n"
     ]
    }
   ],
   "source": [
    "# print(azure_chat_model.streaming)\n",
    "# print(azure_chat_model.callback_manager)\n",
    "\n",
    "azure_chat_model.streaming = True\n",
    "azure_chat_model.callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "azure_chat_model(\n",
    "    [HumanMessage(content=\"Write me a kids scifi story, starts with 'Once upon a time...'\")],\n",
    "    # stop=[\"\\n\", \"Human:\", \"AI:\"],\n",
    "    )\n",
    "\n",
    "print('The End!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI21',\n",
       " 'AlephAlpha',\n",
       " 'Anthropic',\n",
       " 'AzureOpenAI',\n",
       " 'Banana',\n",
       " 'BaseLLM',\n",
       " 'CerebriumAI',\n",
       " 'Cohere',\n",
       " 'DeepInfra',\n",
       " 'Dict',\n",
       " 'ForefrontAI',\n",
       " 'GPT4All',\n",
       " 'GooseAI',\n",
       " 'HuggingFaceEndpoint',\n",
       " 'HuggingFaceHub',\n",
       " 'HuggingFacePipeline',\n",
       " 'LlamaCpp',\n",
       " 'Modal',\n",
       " 'NLPCloud',\n",
       " 'OpenAI',\n",
       " 'OpenAIChat',\n",
       " 'Petals',\n",
       " 'PromptLayerOpenAI',\n",
       " 'PromptLayerOpenAIChat',\n",
       " 'RWKV',\n",
       " 'Replicate',\n",
       " 'SagemakerEndpoint',\n",
       " 'SelfHostedHuggingFaceLLM',\n",
       " 'SelfHostedPipeline',\n",
       " 'StochasticAI',\n",
       " 'Type',\n",
       " 'Writer',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'ai21',\n",
       " 'aleph_alpha',\n",
       " 'anthropic',\n",
       " 'bananadev',\n",
       " 'base',\n",
       " 'cerebriumai',\n",
       " 'cohere',\n",
       " 'deepinfra',\n",
       " 'forefrontai',\n",
       " 'gooseai',\n",
       " 'gpt4all',\n",
       " 'huggingface_endpoint',\n",
       " 'huggingface_hub',\n",
       " 'huggingface_pipeline',\n",
       " 'llamacpp',\n",
       " 'loading',\n",
       " 'modal',\n",
       " 'nlpcloud',\n",
       " 'openai',\n",
       " 'petals',\n",
       " 'promptlayer_openai',\n",
       " 'replicate',\n",
       " 'rwkv',\n",
       " 'sagemaker_endpoint',\n",
       " 'self_hosted',\n",
       " 'self_hosted_hugging_face',\n",
       " 'stochasticai',\n",
       " 'type_to_cls_dict',\n",
       " 'utils',\n",
       " 'writer']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(langchain.llms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_openai_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
