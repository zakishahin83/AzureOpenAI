{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import langchain\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage, \n",
    "    AIMessage, \n",
    "    ChatMessage,\n",
    "    ChatResult,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    AIMessagePromptTemplate,\n",
    "\n",
    ")\n",
    "\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_modelid_4k = os.environ.get('GPT4_MODELID_4K')\n",
    "gpt4_key = os.environ.get('GPT4_KEY')\n",
    "gpt4_endpoint = os.environ.get('GPT4_ENDPOINT')\n",
    "gpt4_api_version = os.environ.get('GPT4_API_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_stream = AzureChatOpenAI(\n",
    "    deployment_name=gpt4_modelid_4k,\n",
    "    model_name=gpt4_modelid_4k,\n",
    "    openai_api_key=gpt4_key,\n",
    "    openai_api_base=gpt4_endpoint,\n",
    "    openai_api_version=gpt4_api_version,\n",
    "    streaming=True, \n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), \n",
    "    verbose=True, \n",
    "    temperature=0, \n",
    "    max_tokens=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning! I hope you're having a great day so far. How can I help you today?"
     ]
    }
   ],
   "source": [
    "resp = chat_stream(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Morning?\"\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi modal demo \n",
    "explain a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    \"https://live.staticflickr.com/5011/5507036385_dccd3cd6f8_b.jpg\", \n",
    "    \"http://freebie.photography/sport/gaming_dice.jpg\", \n",
    "    \"https://www.paindepices.fr/pub/MINIATURES/ENFANT/.ED42_DES-MINIATURES_m.jpg\",  \n",
    "    \"https://cdn.sanity.io/images/68sc9ce8/production/8983fcac4e20d38f7a46d7e63844d37d257696a0-728x419.png?w=2000&fit=max\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"you are a helpful AI assistant, you accept multimodal input. your responses are short and concise.\"\n",
    "    \n",
    "human_template = \"Please caption the image in this URL: {image}. \"\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_template), \n",
    "        HumanMessagePromptTemplate.from_template(human_template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://live.staticflickr.com/5011/5507036385_dccd3cd6f8_b.jpg\n",
      "\"Lonely bench on a snowy day surrounded by leafless trees\"\n",
      "http://freebie.photography/sport/gaming_dice.jpg\n",
      "Gaming dice scattered randomly on a wooden surface.\n",
      "https://www.paindepices.fr/pub/MINIATURES/ENFANT/.ED42_DES-MINIATURES_m.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children playing with colorful miniature wooden toys.\n",
      "https://cdn.sanity.io/images/68sc9ce8/production/8983fcac4e20d38f7a46d7e63844d37d257696a0-728x419.png?w=2000&fit=max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Silhouette of a skateboarder performing a trick during a vibrant sunset\"\n"
     ]
    }
   ],
   "source": [
    "for image in images:\n",
    "        \n",
    "        print(image)\n",
    "        chat_stream( \n",
    "              chat_prompt.format_prompt(\n",
    "              image = image\n",
    "              ).to_messages()\n",
    "        )\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_dalle_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
