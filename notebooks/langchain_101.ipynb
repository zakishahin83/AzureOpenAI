{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_endpoint: https://lnc-eastus-openai.openai.azure.com/\n",
      "gpt4_key: **********\n",
      "gpt4_region: eastus\n",
      "gpt4_modelid_4k: gpt-4-0314\n",
      "gpt4_modelid_32k: gpt-4-32k-0314\n",
      "gpt4_api_version: 2023-03-15-preview\n",
      "chatgpt_api_key: **********\n",
      "chatgpt_region: southcentralus\n",
      "chatgpt_endpoint: https://magopenai.openai.azure.com/\n",
      "oai_api_key: **********\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import utils.openai_env as oai_env\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# get above env variables using os.environ.get and use provided values as defaults\n",
    "gpt4_endpoint = os.environ.get('gpt4_endpoint', 'https://lnc-eastus-openai.openai.azure.com/')\n",
    "gpt4_key = os.environ.get('gpt4_key', '121221')\n",
    "gpt4_region = os.environ.get('gpt4_region', 'eastus')\n",
    "gpt4_modelid_4k = os.environ.get('gpt4_modelid_4k', 'gpt-4-0314')\n",
    "gpt4_modelid_32k = os.environ.get('gpt4_modelid_32k', 'gpt-4-32k-0314')\n",
    "gpt4_api_version = os.environ.get('gpt4_api_version', '2023-03-15-preview')\n",
    "\n",
    "\n",
    "# get the above from os.environ.get and use provided values as defaults\n",
    "chatgpt_api_key = os.environ.get('chatgpt_api_key', '121212121212')\n",
    "chatgpt_region = os.environ.get('chatgpt_region', 'southcentralus')\n",
    "chatgpt_endpoint = os.environ.get('chatgpt_endpoint', 'https://magopenai.openai.azure.com/')\n",
    "\n",
    "oai_api_key = os.environ.get('oai_api_key', '121212121212')\n",
    "\n",
    "print(f'gpt4_endpoint: {gpt4_endpoint}')\n",
    "print(f'gpt4_key: **********')\n",
    "print(f'gpt4_region: {gpt4_region}')\n",
    "print(f'gpt4_modelid_4k: {gpt4_modelid_4k}')\n",
    "print(f'gpt4_modelid_32k: {gpt4_modelid_32k}')\n",
    "print(f'gpt4_api_version: {gpt4_api_version}')\n",
    "print(f'chatgpt_api_key: **********')\n",
    "print(f'chatgpt_region: {chatgpt_region}')\n",
    "print(f'chatgpt_endpoint: {chatgpt_endpoint}')\n",
    "print(f'oai_api_key: **********')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic text completion with a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: None\n",
      "openai.api_key: **********kKkw\n",
      "openai.api_base: https://api.openai.com/v1\n",
      "openai.api_type: open_ai\n",
      "openai.api_version: None\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/en/latest/reference/modules/llms.html#langchain.llms.AzureOpenAI\n",
    "\n",
    "from langchain import OpenAI\n",
    "# os.environ['OPENAI_API_KEY'] = oai_api_key\n",
    "llm = OpenAI(openai_api_key=oai_api_key, verbose=True)\n",
    "\n",
    "oai_env.print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nTuesday'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What comes after Monday? \"\n",
    "llm(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"Question: {question}\\n\\n\"\n",
    "\"Answer:\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"],)\n",
    "\n",
    "question = \"once upon a time, in a galaxy far far away ... \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: once upon a time, in a galaxy far far away ... \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'once upon a time, in a galaxy far far away ... ', 'text': '\\nAnswer: A long time ago in a galaxy far, far awayâ€¦there lived a brave and noble hero who was determined to save his people from a dark and powerful enemy. With the help of a wise sage, a loyal companion, and some unexpected allies, the hero embarked on a quest to find the courage and strength to defeat the enemy and restore hope to the galaxy.'}\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain(question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking Multiple Questions with LLM chain and generate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [\n",
    "    {'question': \"What is the capital of Australia?\"},\n",
    "    {'question': \"Monday, Tuesday, ... ?\"},\n",
    "    {'question': \"what day of week is 33 of December 2019?\"},\n",
    "    {'question': \"is 33 of December 2019 a correct date?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the capital of Australia?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Monday, Tuesday, ... ?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: what day of week is 33 of December 2019?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: is 33 of December 2019 a correct date?\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = llm_chain.generate(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The capital of Australia is Canberra.\n",
      "\n",
      "Answer: Wednesday, Thursday, Friday.\n",
      "\n",
      "Answer: Tuesday.\n",
      "\n",
      "Answer: No, December 33 is not a correct date.\n"
     ]
    }
   ],
   "source": [
    "for r in res.generations:\n",
    "    print(r[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat Scenario \n",
    "#https://blog.langchain.dev/chat-models/ \n",
    "#https://python.langchain.com/en/latest/modules/chains/getting_started.html?highlight=chatopenai#query-an-llm-with-the-llmchain \n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI, ChatAzureOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ChatOpenAI for basic chat prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: None\n",
      "openai.api_key: **********kKkw\n",
      "openai.api_base: https://api.openai.com/v1\n",
      "openai.api_type: open_ai\n",
      "openai.api_version: None\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/en/latest/modules/models/chat/getting_started.html\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate, \n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import ( \n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "\n",
    "oai_env.print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, openai_api_key= openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to Arabic. I love artificial intelligence.\")\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'aime programmer.\n",
      "-----\n",
      "Ø£Ù†Ø§ Ø£Ø­Ø¨ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\n",
      "-----\n",
      "{'token_usage': {'prompt_tokens': 73, 'completion_tokens': 24, 'total_tokens': 97}, 'model_name': 'gpt-3.5-turbo'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iterate over list of generations, unpack item number and generation item \n",
    "for i, generation in enumerate(result.generations):\n",
    "   \n",
    "    # iterate over list of messages in generation\n",
    "    for g in generation:\n",
    "        # print the message content\n",
    "        print(g.text)\n",
    "    # print a separator\n",
    "    print(\"-----\")\n",
    "\n",
    "\n",
    "\n",
    "print(result.llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Chat Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a faraway galaxy, there was a planet called Zorax. Zorax was a beautiful planet with lush green forests, sparkling blue oceans, and towering mountains. The inhabitants of Zorax were a friendly and peaceful race of aliens called Zoraxians.\n",
      "\n",
      "One day, a group of Zoraxian children were playing in the forest when they stumbled upon a strange object. It was a small spaceship that had crash-landed on their planet. The children were curious and decided to investigate.\n",
      "\n",
      "As they approached the spaceship, they heard a faint beeping sound coming from inside. They cautiously opened the door and found a tiny robot inside. The robot was damaged and needed repairs.\n",
      "\n",
      "The children took the robot back to their village and showed it to their parents. The Zoraxians were amazed by the robot and decided to help repair it. They worked tirelessly for days, fixing the robot's circuits and replacing its damaged parts.\n",
      "\n",
      "Finally, the robot was fixed, and it sprang to life. It introduced itself as Robo, a robot from a distant planet. Robo had been sent on a mission to explore the universe and gather information about different planets.\n",
      "\n",
      "The Zoraxians were excited to learn more about the universe and asked Robo to take them on a journey through space. Robo agreed and took the children on an incredible adventure through the galaxy.\n",
      "\n",
      "They visited different planets, met strange creatures, and saw amazing sights. They even visited Robo's home planet and met other robots like him.\n",
      "\n",
      "The Zoraxian children were thrilled with their adventure and couldn't wait to tell their friends and family about their journey through space. They had learned so much about the universe and had made a new friend in Robo.\n",
      "\n",
      "From that day on, the Zoraxians continued to explore the universe, always looking for new adventures and new friends to meet. And Robo was always there to guide them on their journey."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "chat_stream = ChatOpenAI(\n",
    "    openai_api_key=openai.api_key,\n",
    "    streaming=True, \n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), \n",
    "    verbose=True, \n",
    "    temperature=0)\n",
    "resp = chat_stream([HumanMessage(content=\"Write me a kids scifi story, starts with 'Once upon a time...'\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using prompt templates and chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_dalle_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
